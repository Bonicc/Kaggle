{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 호출하기\n",
    "- pandas 를 이용해서 데이터를 불러오고, 데이터 전처리 및 tokenize를 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              question  \\\n",
       "0               hi, how are you doing?   \n",
       "1        i'm fine. how about yourself?   \n",
       "2  i'm pretty good. thanks for asking.   \n",
       "3    no problem. so how have you been?   \n",
       "4     i've been great. what about you?   \n",
       "\n",
       "                                     answer  \n",
       "0             i'm fine. how about yourself?  \n",
       "1       i'm pretty good. thanks for asking.  \n",
       "2         no problem. so how have you been?  \n",
       "3          i've been great. what about you?  \n",
       "4  i've been good. i'm in school right now.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dialogs.txt\",delimiter = \"\\t\", encoding = \"UTF-8\", names = [\"question\", \"answer\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(sentence):\n",
    "    # 줄임말 늘려놓기\n",
    "    sentence = re.sub(pattern = \"i'm\",    repl = \"i am\",      string = sentence)  \n",
    "    sentence = re.sub(pattern = \"you're\", repl = \"you are\",   string = sentence)\n",
    "    sentence = re.sub(pattern = \"it's\",   repl = \"it is\",     string = sentence)\n",
    "    sentence = re.sub(pattern = \"he's\",   repl = \"he is\",     string = sentence)\n",
    "    sentence = re.sub(pattern = \"she's\",  repl = \"she is\",    string = sentence)\n",
    "    \n",
    "    sentence = re.sub(pattern = \"where's\",repl = \"where is\",  string = sentence)\n",
    "    sentence = re.sub(pattern = \"what's\", repl = \"what is\",   string = sentence)\n",
    "    sentence = re.sub(pattern = \"that's\", repl = \"that is\",   string = sentence)\n",
    "    \n",
    "    sentence = re.sub(pattern = \"'ve\",    repl = \" have\",     string = sentence)\n",
    "    sentence = re.sub(pattern = \"'ll\",    repl = \" will\",     string = sentence)\n",
    "        \n",
    "    sentence = re.sub(pattern = r\"([?!,.])\",    repl = r\" \\1\",     string = sentence) # !?,. 특수문자 글자와 뗴어놓기\n",
    "    sentence = re.sub(pattern = r\"([' ']+)\",    repl = r\" \",       string = sentence) # 띄어쓰기 중복되는거 하나로\n",
    "    sentence = re.sub(pattern = r\"([^A-z1-9?!,.]+)\",    repl = r\" \",       string = sentence) # 영, 숫자 및 !?,. 빼곤 다 공백으로 처리\n",
    "    \n",
    "    sentence = sentence.strip() # 최종적으로 문자열 양옆의 공백 처리\n",
    "    sentence = \"<start> \" + sentence + \" <end>\"\n",
    "    \n",
    "    return sentence.split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>pro_que</th>\n",
       "      <th>pro_ans</th>\n",
       "      <th>inputs_token</th>\n",
       "      <th>targets_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>[&lt;start&gt;, hi, ,, how, are, you, doing, ?, &lt;end&gt;]</td>\n",
       "      <td>[&lt;start&gt;, i, am, fine, ., how, about, yourself...</td>\n",
       "      <td>[1, 3, 4, 5, 6, 7, 8, 9, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 10, 11, 12, 13, 5, 14, 15, 9, 2, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>[&lt;start&gt;, i, am, fine, ., how, about, yourself...</td>\n",
       "      <td>[&lt;start&gt;, i, am, pretty, good, ., thanks, for,...</td>\n",
       "      <td>[1, 10, 11, 12, 13, 5, 14, 15, 9, 2, 0, 0, 0, ...</td>\n",
       "      <td>[1, 10, 11, 16, 17, 13, 18, 19, 20, 13, 2, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>[&lt;start&gt;, i, am, pretty, good, ., thanks, for,...</td>\n",
       "      <td>[&lt;start&gt;, no, problem, ., so, how, have, you, ...</td>\n",
       "      <td>[1, 10, 11, 16, 17, 13, 18, 19, 20, 13, 2, 0, ...</td>\n",
       "      <td>[1, 21, 22, 13, 23, 5, 24, 7, 25, 9, 2, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>[&lt;start&gt;, no, problem, ., so, how, have, you, ...</td>\n",
       "      <td>[&lt;start&gt;, i, have, been, great, ., what, about...</td>\n",
       "      <td>[1, 21, 22, 13, 23, 5, 24, 7, 25, 9, 2, 0, 0, ...</td>\n",
       "      <td>[1, 10, 24, 25, 26, 13, 27, 14, 7, 9, 2, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "      <td>[&lt;start&gt;, i, have, been, great, ., what, about...</td>\n",
       "      <td>[&lt;start&gt;, i, have, been, good, ., i, am, in, s...</td>\n",
       "      <td>[1, 10, 24, 25, 26, 13, 27, 14, 7, 9, 2, 0, 0,...</td>\n",
       "      <td>[1, 10, 24, 25, 17, 13, 10, 11, 28, 29, 30, 31...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              question  \\\n",
       "0               hi, how are you doing?   \n",
       "1        i'm fine. how about yourself?   \n",
       "2  i'm pretty good. thanks for asking.   \n",
       "3    no problem. so how have you been?   \n",
       "4     i've been great. what about you?   \n",
       "\n",
       "                                     answer  \\\n",
       "0             i'm fine. how about yourself?   \n",
       "1       i'm pretty good. thanks for asking.   \n",
       "2         no problem. so how have you been?   \n",
       "3          i've been great. what about you?   \n",
       "4  i've been good. i'm in school right now.   \n",
       "\n",
       "                                             pro_que  \\\n",
       "0   [<start>, hi, ,, how, are, you, doing, ?, <end>]   \n",
       "1  [<start>, i, am, fine, ., how, about, yourself...   \n",
       "2  [<start>, i, am, pretty, good, ., thanks, for,...   \n",
       "3  [<start>, no, problem, ., so, how, have, you, ...   \n",
       "4  [<start>, i, have, been, great, ., what, about...   \n",
       "\n",
       "                                             pro_ans  \\\n",
       "0  [<start>, i, am, fine, ., how, about, yourself...   \n",
       "1  [<start>, i, am, pretty, good, ., thanks, for,...   \n",
       "2  [<start>, no, problem, ., so, how, have, you, ...   \n",
       "3  [<start>, i, have, been, great, ., what, about...   \n",
       "4  [<start>, i, have, been, good, ., i, am, in, s...   \n",
       "\n",
       "                                        inputs_token  \\\n",
       "0  [1, 3, 4, 5, 6, 7, 8, 9, 2, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [1, 10, 11, 12, 13, 5, 14, 15, 9, 2, 0, 0, 0, ...   \n",
       "2  [1, 10, 11, 16, 17, 13, 18, 19, 20, 13, 2, 0, ...   \n",
       "3  [1, 21, 22, 13, 23, 5, 24, 7, 25, 9, 2, 0, 0, ...   \n",
       "4  [1, 10, 24, 25, 26, 13, 27, 14, 7, 9, 2, 0, 0,...   \n",
       "\n",
       "                                       targets_token  \n",
       "0  [1, 10, 11, 12, 13, 5, 14, 15, 9, 2, 0, 0, 0, ...  \n",
       "1  [1, 10, 11, 16, 17, 13, 18, 19, 20, 13, 2, 0, ...  \n",
       "2  [1, 21, 22, 13, 23, 5, 24, 7, 25, 9, 2, 0, 0, ...  \n",
       "3  [1, 10, 24, 25, 26, 13, 27, 14, 7, 9, 2, 0, 0,...  \n",
       "4  [1, 10, 24, 25, 17, 13, 10, 11, 28, 29, 30, 31...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"pro_que\"] = df['question'].map(lambda x: preprocess_string(x))\n",
    "df[\"pro_ans\"] = df['answer'].map(lambda x: preprocess_string(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Tokenize and Padding\n",
    "- 데이터를 숫자로 Tokenize, 이후에 길이를 맞추기 위해 padding을 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_token = {\"<padding>\" : 0, \"<start>\" : 1, \"<end>\" : 2}\n",
    "max_length = 25\n",
    "\n",
    "def tokenize(sentence, training = True):\n",
    "    tokenized_sentence = []\n",
    "    \n",
    "    if training:\n",
    "        for word in sentence:\n",
    "            try :\n",
    "                tokenized_sentence.append(word_to_token[word])\n",
    "            except:\n",
    "                word_to_token[word] = len(word_to_token)\n",
    "                tokenized_sentence.append(word_to_token[word])\n",
    "    else:\n",
    "        for word in sentence:\n",
    "            try :\n",
    "                tokenized_sentence.append(word_to_token[word])\n",
    "            except:\n",
    "                print(\"<Error!> : There is no Token for \"+word+\"! Please try again\")\n",
    "                raise NotImplementedError\n",
    "    \n",
    "    return tokenized_sentence\n",
    "\n",
    "def padding(tokenized_sentence, max_length):\n",
    "    if len(tokenized_sentence) > max_length:\n",
    "        print(\"<Error!> : max_length is small then sentence! please input bigger max_length !\")\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    while len(tokenized_sentence) < max_length:\n",
    "        tokenized_sentence.append(0)\n",
    "    return tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['inputs_token'] = df['pro_que'].map(tokenize).map(lambda x: padding(x, max_length))\n",
    "df['targets_token'] = df['pro_ans'].map(tokenize).map(lambda x: padding(x, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_word = {word_to_token[i] : i for i in word_to_token}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 만들기\n",
    "- Encoder Model\n",
    "- Attention Model\n",
    "- Decoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder 모델 정의\n",
    "- Encoder는 입력 sequence 를 받아들이고, hidden state 및 output을 생성한다.\n",
    "- 즉 채팅시에 상대방이 입력하는 입력값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 units, # encoder로 들어오는 unit의 개수\n",
    "                 vocab_size, # 임베딩전 단어의 개수\n",
    "                 embedding_units): # 임베딩 한 유닛의 개수\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = units \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_units) \n",
    "                \n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        \n",
    "    def __call__(self, x, hidden = None):\n",
    "        x = self.embedding(x)\n",
    "        if hidden == None:\n",
    "            hidden = tf.zeros([x.shape[0],self.enc_units])\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention 모델 정의\n",
    "- Attention은 Encoder의 output(hidden state) 들에서 주의해야할 부분을 추출해 Decoder에 입력으로써 사용된다.\n",
    "- RNN의 특징인 gradient banishing problem 을 제거하기 위한 방법\n",
    "- BahdanauAttention을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w1 = tf.keras.layers.Dense(units)\n",
    "        self.w2 = tf.keras.layers.Dense(units)\n",
    "        self.v = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def __call__(self, \n",
    "                 query, # decoder의 t-1에서의 output\n",
    "                 values): # encoder의 output들\n",
    "        \n",
    "        query = tf.expand_dims(query, 1) # query 는 decoder의 output 1개이므로, 이후에 연산을 위해 dimention 1 추가\n",
    "        score = self.v(tf.nn.tanh(self.w1(query) + self.w2(values))) # Encoder Cell 별 점수\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(score, axis = 1) # Encoder cell 별 weight(점수 기반)\n",
    "        \n",
    "        context_vector = attention_weights * values \n",
    "        context_vector = tf.reduce_sum(context_vector, axis = 1) # \n",
    "        \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder 모델 정의\n",
    "- Decoder 는 이전의 output(output of t-1)의 값을 입력으로 다시 받는 RNN 모델\n",
    "- BahdanauAttention 사용 시에는 각 입력값에 context_vector 가 추가된 값이 들어가 Encoder의 중요 cell의 가중치를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 units, # encoder로 들어오는 unit의 개수\n",
    "                 vocab_size, # 임베딩전 단어의 개수\n",
    "                 embedding_units): # 임베딩 한 유닛의 개수\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = units \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_units) \n",
    "                \n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        \n",
    "        self.fc = tf.keras.layers.Dense(vocab_size) # hidden_state 에서 특정 단어로 만들어주는 layer\n",
    "                \n",
    "        self.attention = BahdanauAttention(units) \n",
    "        \n",
    "    def __call__(self, x, # 시간 t에 대한 1개의 sequence를 가진 input, shape of (batch_size, 1, embedding_units)\n",
    "                 hidden, # t-1 시간의 hidden_state, initial hidden_state 는 encoder의 마지막 hidden_state\n",
    "                 enc_output): # attention에 넣을 encoder output들(hidden_state들)\n",
    "        \n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        \n",
    "        x = self.embedding(x) # shape of (batch_size, 1, embedding_units)\n",
    "                \n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1),x],axis = -1)\n",
    "        # context vector shape (batch_size, hidden_state) 이므로 x와 concat 하기 위해 축 1개 추가\n",
    "        \n",
    "        output, state = self.gru(x)        \n",
    "        output = tf.reshape(output, (-1, output.shape[2])) # fc에 넣기 위해 shape 조정\n",
    "        \n",
    "        x = self.fc(output) # shape of (batch_size, vocab_size)\n",
    "        \n",
    "        return x, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정의한 모델 확인\n",
    "- Encoder \n",
    "- Attention\n",
    "- Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "units = 1024\n",
    "vocab_size = len(word_to_token)\n",
    "embedding_units = 256\n",
    "\n",
    "inputs = pd.DataFrame(df.inputs_token.tolist(), index= df.index).values\n",
    "targets = pd.DataFrame(df.targets_token.tolist(), index= df.index).values\n",
    "\n",
    "steps = len(inputs)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_output shape :  (64, 25, 1024)\n",
      "enc_hidden shape :  (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(units,vocab_size,embedding_units)\n",
    "enc_output, enc_hidden = encoder(inputs[:batch_size])\n",
    "\n",
    "print(\"enc_output shape : \", enc_output.shape)\n",
    "print(\"enc_hidden shape : \", enc_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vector shape :  (64, 1024)\n",
      "attention_weights shape :  (64, 25, 1)\n"
     ]
    }
   ],
   "source": [
    "attention = BahdanauAttention(units)\n",
    "context_vector, attention_weights = attention(enc_hidden, enc_output)\n",
    "\n",
    "print(\"context_vector shape : \", context_vector.shape)\n",
    "print(\"attention_weights shape : \", attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec_output shape :  (64, 2442)\n",
      "dec_hidden shape :  (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(units, vocab_size, embedding_units)\n",
    "dec_output, dec_hidden = decoder(targets[:batch_size,:1], enc_hidden, enc_output)\n",
    "\n",
    "\n",
    "print(\"dec_output shape : \", dec_output.shape)\n",
    "print(\"dec_hidden shape : \", dec_hidden.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function 정의 및 Train step 정의\n",
    "- Loss Function : \n",
    "- Train step :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, hypothesis):    \n",
    "    #mask = tf.math.logical_not(tf.math.equal(real, 0))   # <padding> 일 경우에는 loss값을 얻지 않기 위한 mask\n",
    "    loss_ = loss_object(real, hypothesis)\n",
    "    \n",
    "    #mask = tf.cast(mask, dtype=loss_.dtype) # mask 와 loss 를 곱해주기 위해 type 변경\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(dataset):\n",
    "    loss = 0        \n",
    "    \n",
    "    train_input, train_target = dataset        \n",
    "    max_length = train_target.shape[1]\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(train_input)\n",
    "        \n",
    "        dec_hidden = enc_hidden \n",
    "        dec_input = tf.ones([train_target.shape[0], 1])\n",
    "        \n",
    "        for t in range(max_length):\n",
    "            prediction, dec_hidden = decoder(dec_input, dec_hidden, enc_output)\n",
    "            \n",
    "            loss += loss_function(train_target[:,t:t+1], prediction)\n",
    "            \n",
    "            dec_input = train_target[:, t:t+1]\n",
    "    \n",
    "    batch_loss = loss / max_length\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    \n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients,variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(inputs, targets):\n",
    "    random_index = np.arange(inputs.shape[0])\n",
    "    np.random.shuffle(random_index)\n",
    "    \n",
    "    return inputs[random_index], targets[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epochs 0, total loss is 137.5696258544922\n",
      "At epochs 1, total loss is 104.12376403808594\n",
      "At epochs 2, total loss is 91.54669952392578\n",
      "At epochs 3, total loss is 86.08834075927734\n",
      "At epochs 4, total loss is 80.7868423461914\n",
      "At epochs 5, total loss is 75.60708618164062\n",
      "At epochs 6, total loss is 68.64096069335938\n",
      "At epochs 7, total loss is 61.661014556884766\n",
      "At epochs 8, total loss is 67.09258270263672\n",
      "At epochs 9, total loss is 53.725791931152344\n",
      "At epochs 10, total loss is 49.47429275512695\n",
      "At epochs 11, total loss is 42.28331756591797\n",
      "At epochs 12, total loss is 37.978118896484375\n",
      "At epochs 13, total loss is 32.945587158203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-18-2219446bc887>\", line 8, in <module>\n",
      "    loss = train_step(batched_dataset)\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 828, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 855, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2943, in __call__\n",
      "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1919, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 560, in call\n",
      "    ctx=ctx)\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 60, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"c:\\users\\mnl431\\anaconda3\\envs\\tensorflow2.0\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for e in range(epochs+1):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for s in range(steps):\n",
    "        batched_dataset = (inputs[batch_size * s: batch_size * s+1], targets[batch_size * s: batch_size * s+1])\n",
    "        loss = train_step(batched_dataset)\n",
    "        total_loss += loss\n",
    "        \n",
    "    print(\"At epochs {}, total loss is {}\".format(e, total_loss))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with question\n",
    "- 모델 학습이 되었는지 채팅으로 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize(tokenized_sentence):\n",
    "    sentence = []\n",
    "    for index in tokenized_sentence:\n",
    "        index = int(index)\n",
    "        sentence.append(token_to_word[index])\n",
    "    return sentence\n",
    "\n",
    "def cut_from_start_to_end(sentence):\n",
    "    answer = []\n",
    "    for word in sentence:\n",
    "        if word != '<start>' and word != \"<end>\":\n",
    "            answer.append(word)\n",
    "        elif word == \"<end>\":\n",
    "            break\n",
    "    return \" \".join(answer)\n",
    "    \n",
    "def chat(question):\n",
    "    question = preprocess_string(question)\n",
    "    question = tokenize(question,training = False)\n",
    "    question = padding(question, max_length)\n",
    "    \n",
    "    question = tf.expand_dims(question,0)\n",
    "    \n",
    "    answer = []\n",
    "    \n",
    "    enc_output, enc_hidden = encoder(question)\n",
    "\n",
    "    dec_hidden = enc_hidden \n",
    "    dec_input = tf.ones([1, 1]) # <start> as input\n",
    "\n",
    "    for t in range(max_length):\n",
    "        answer.append(dec_input[0][0])\n",
    "        prediction, dec_hidden = decoder(dec_input, dec_hidden, enc_output)\n",
    "        dec_input = tf.expand_dims(tf.argmax(prediction,axis = 1),0)\n",
    "    \n",
    "    answer = detokenize(answer)\n",
    "    answer = cut_from_start_to_end(answer)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: hi, how are you doing? \n",
      "answer\t: i am fine . how about yourself ?\n",
      "question: i'm fine. how about yourself? \n",
      "answer\t: i would wait to find something long .\n",
      "question: i'm pretty good. thanks for asking. \n",
      "answer\t: i would wait to find something long .\n",
      "question: no problem. so how have you been? \n",
      "answer\t: i don t wait to take five wipes .\n",
      "question: i've been great. what about you? \n",
      "answer\t: i would wait to find something long .\n",
      "question: i've been good. i'm in school right now. \n",
      "answer\t: i would wait to find something long .\n",
      "question: what school do you go to? \n",
      "answer\t: i would wait to find something lock their doors ?\n",
      "question: i go to pcc. \n",
      "answer\t: i would wait to find something long .\n",
      "question: do you like it there? \n",
      "answer\t: i am going to take five wipes .\n",
      "question: it's okay. it's a really big campus. \n",
      "answer\t: i wouldn t wait to find something closer to find something closer to find something closer to find something closer to find something\n",
      "question: good luck with school. \n",
      "answer\t: i would wait to take five wipes .\n",
      "question: how's it going? \n",
      "answer\t: i am going to take five wipes .\n",
      "question: i'm doing well. how about you? \n",
      "answer\t: i would wait to find something long .\n",
      "question: never better, thanks. \n",
      "answer\t: i would wait to find something long .\n",
      "question: so how have you been lately? \n",
      "answer\t: i would wait to take five wipes .\n",
      "question: i've actually been pretty good. you? \n",
      "answer\t: i would wait to find something long .\n",
      "question: i'm actually in school right now. \n",
      "answer\t: i would wait to find something long .\n",
      "question: which school do you attend? \n",
      "answer\t: i would wait to take five wipes .\n",
      "question: i'm attending pcc right now. \n",
      "answer\t: i would wait to find something long .\n",
      "question: are you enjoying it there? \n",
      "answer\t: i would wait to take five wipes .\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    question = df.question.loc[i]\n",
    "    print(\"question:\",question,\"\\nanswer\\t:\",chat(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
